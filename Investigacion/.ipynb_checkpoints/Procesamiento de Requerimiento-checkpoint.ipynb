{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procesamiento de Requerimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJETIVO\n",
    "El objetivo que se persigue es poder descubrir dentro del texto del requerimiento, cuales son las tareas a realizar y explorar el contexto relacionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías\n",
    "Las librería principal a utilizar es <a href=\"http://www.nltk.org/\" target=\"_blanck\"> <b>nltk</b> </a>.\n",
    "<br>Nltk es una plataforma que brinda herramientas para el procesamiento del lenguaje natural, como clasificadores, etiquetadores, analizadores semanticos y sintacticos, etc.\n",
    "\n",
    "<b>Glosario relacionado</b>\n",
    "<br>\n",
    "<u>Corpus</u>: es una coleccion de docuementos sobre un tema en particular.\n",
    "<br>\n",
    "<u>Corpora</u>: es un conjunto de Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# corpora español\n",
    "from nltk.corpus import cess_esp as cess\n",
    "# tokenize divide un string en substrings (ejemplo: palabras u oraciones)\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separador de horaciones para idioma español\n",
    "spanish_sentence_tokenizer = nltk.data.load('tokenizers/punkt/spanish.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etiquetador\n",
    "Se define las funciones para <b>crear el etiquetador</b> y para <b>etiquetar el texto</b> a trabajar.\n",
    "<br>\n",
    "<b>trigram_tagger:</b> es un etiquetador que recibe como parametro el texto para entrenamiento. Este etiquetador se basa en ...(estudiar los unigram, bigram y trigram para describir el funcionamiento)\n",
    "<br>\n",
    "<b>tag_sentences:</b> es una funcion que recibe el etiquetador, el separador de horaciones (preparado para idioma español) y el texto a etiquetar. Retorna las palabras del texto etiquetadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigram_tagger(training_set):\n",
    "   default_tagger = nltk.DefaultTagger('NN')\n",
    "   unigram_tagger = nltk.UnigramTagger(training_set, backoff=default_tagger)\n",
    "   bigram_tagger = nltk.BigramTagger(training_set, backoff=unigram_tagger)\n",
    "   return nltk.TrigramTagger(training_set, backoff=bigram_tagger)\n",
    "\n",
    "def tag_sentences(tagger, sentence_tokenizer, sentences):\n",
    "   tokenized_sentences = sentence_tokenizer.tokenize(sentences)\n",
    "   return [tagger.tag(word_tokenize(s)) for s in tokenized_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Entreno el etiquetador con un corpus en español\n",
    "tagger = trigram_tagger(cess.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Poner', 'vmn0000'), ('un', 'di0ms0'), ('botón', 'ncms000'), ('en', 'sps00'), ('la', 'da0fs0'), ('pantalla', 'ncfs000'), ('de', 'sps00'), ('tramites', 'NN'), ('y', 'cc'), ('luego', 'rg'), ('eliminar', 'vmn0000'), ('el', 'da0ms0'), ('filtro', 'ncms000'), ('de', 'sps00'), ('cuil', 'NN'), ('de', 'sps00'), ('la', 'da0fs0'), ('pantalla', 'ncfs000'), ('Pensiones', 'NN'), ('y', 'cc'), ('quitar', 'vmn0000'), ('el', 'da0ms0'), ('titulo', 'NN'), ('a', 'sps00'), ('la', 'da0fs0'), ('pagina', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "# Pruebo el modelo e imprimo las etiquetas de cada palabra procesada\n",
    "texto = \"Poner un botón en la pantalla de tramites y luego eliminar el filtro de \\\n",
    "cuil de la pantalla Pensiones y quitar el titulo a la pagina\"\n",
    "print(tag_sentences(tagger, spanish_sentence_tokenizer, texto))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patrones\n",
    "Se busca patrones en el texto, que cumplan con una cierta composicion gramatical.\n",
    "<br>\n",
    "Se define la funcion <b>tag_sentences_chunk</b> para encontrar patrones de texto que esten relacionados a la ejecucion de una accion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tag_sentences_chunk(tagger, sentence_tokenizer, sentences):\n",
    "    tokenized_sentences = sentence_tokenizer.tokenize(sentences)\n",
    "    try:\n",
    "        for i in tokenized_sentences:\n",
    "            words = nltk.word_tokenize(i)\n",
    "            tagged = tagger.tag(words)\n",
    "            \n",
    "            #busco el patron\n",
    "            chunkGram = r\"\"\"Accion: {<v.*> <d.*> <n.*> <s.*> <N.*> <s.*> <d.*> <n.*> <N.*>+}\n",
    "                                    {<v.*> <d.*> <n.*> <s.*> <d.*> <n.*> <s.*> <N.*>}\n",
    "                                    {<v.*> <d.*> <n.*> <s.*> <N.*> <s.*> <d.*> <n.*>+}\n",
    "                                    {<v.*> <d.*> <n.*> <s.*> <d.*> <n.*>+} \n",
    "                                    {<v.*> <d.*> <n.*> <s.*> <d.*> <n.*>+}                                    \n",
    "                                    {<v.*> <d.*> <N.*> <s.*> <d.*> <N.*>+}\n",
    "                                    {<v.*> <d.*> <n.*>+}                                    \n",
    "                                    \"\"\"\n",
    "            \n",
    "            # Si quiero eliminar del texto\n",
    "            # chunkGram = r\"\"\"Accion: {<.*>+} \n",
    "            #                         }<d.*|s.*|c.*|r.*>{\"\"\"\n",
    "            chunkParser = nltk.RegexpParser(chunkGram)\n",
    "            chunked = chunkParser.parse(tagged)\n",
    "            \n",
    "            #imprimo los pedazos detectados\n",
    "            print(chunked)\n",
    "            \n",
    "            #imprimo los pedazos detectados del tipo Accion\n",
    "            for subtree in chunked.subtrees(filter=lambda t: t.label() == 'Accion'):\n",
    "                print(subtree)\n",
    "\n",
    "            #grafico el analizis producido\n",
    "            chunked.draw()\n",
    "               \n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (Accion\n",
      "    Poner/vmn0000\n",
      "    un/di0ms0\n",
      "    botón/ncms000\n",
      "    en/sps00\n",
      "    la/da0fs0\n",
      "    pantalla/ncfs000\n",
      "    de/sps00\n",
      "    tramites/NN)\n",
      "  y/cc\n",
      "  luego/rg\n",
      "  (Accion\n",
      "    eliminar/vmn0000\n",
      "    el/da0ms0\n",
      "    filtro/ncms000\n",
      "    de/sps00\n",
      "    cuil/NN\n",
      "    de/sps00\n",
      "    la/da0fs0\n",
      "    pantalla/ncfs000\n",
      "    Pensiones/NN)\n",
      "  y/cc\n",
      "  (Accion\n",
      "    quitar/vmn0000\n",
      "    el/da0ms0\n",
      "    titulo/NN\n",
      "    a/sps00\n",
      "    la/da0fs0\n",
      "    pagina/NN))\n",
      "(Accion\n",
      "  Poner/vmn0000\n",
      "  un/di0ms0\n",
      "  botón/ncms000\n",
      "  en/sps00\n",
      "  la/da0fs0\n",
      "  pantalla/ncfs000\n",
      "  de/sps00\n",
      "  tramites/NN)\n",
      "(Accion\n",
      "  eliminar/vmn0000\n",
      "  el/da0ms0\n",
      "  filtro/ncms000\n",
      "  de/sps00\n",
      "  cuil/NN\n",
      "  de/sps00\n",
      "  la/da0fs0\n",
      "  pantalla/ncfs000\n",
      "  Pensiones/NN)\n",
      "(Accion\n",
      "  quitar/vmn0000\n",
      "  el/da0ms0\n",
      "  titulo/NN\n",
      "  a/sps00\n",
      "  la/da0fs0\n",
      "  pagina/NN)\n"
     ]
    }
   ],
   "source": [
    "# Ejemcuto la funcion para detectar los patrones del texto con alguna accion\n",
    "texto_chunk = \"Poner un botón en la pantalla de tramites y luego eliminar el filtro de cuil de la pantalla Pensiones y quitar el titulo a la pagina\"\n",
    "tag_sentences_chunk(tagger, spanish_sentence_tokenizer, texto_chunk)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
